{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenum = 19\n",
    "expid = 1\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "sleeptime = np.random.rand(1)*10\n",
    "time.sleep(int(sleeptime*100)/100)\n",
    "filehead = 'tf_leaky_result_train_mnist'+str(filenum).zfill(3)+'_'\n",
    "jlist = [int(j.split(filehead)[1].split('.')[0]) for j in os.listdir('.') if j.startswith(filehead) and j.endswith('.log')]\n",
    "if len(jlist)==0:\n",
    "    expid = 1\n",
    "else:\n",
    "    expid = np.max(jlist)+1\n",
    "import torch\n",
    "torch.save(0,filehead + str(expid).zfill(3) + '.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(expid)\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.manual_seed(expid)\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# torch.manual_seed(expid)\n",
    "\n",
    "DOWNLOAD_PATH = '/data/mnist'\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_TEST = 1000\n",
    "\n",
    "transform_mnist = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                                       transform=transform_mnist)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "                                      transform=transform_mnist)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE_TEST, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evens = list(range(0, len(trainset), 2))\n",
    "# odds = list(range(1, len(trainset), 2))\n",
    "trainidx = np.random.permutation(len(train_set))\n",
    "trainidx = trainidx[:6000]\n",
    "trainset = torch.utils.data.Subset(train_set, trainidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, hidden_dim, alpha, channels=3, dim_head = 64):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim)).to(device)\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim).to(device)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim)).to(device)\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim).to(device)\n",
    "\n",
    "        self.to_cls_token = nn.Identity().to(device)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim).to(device),\n",
    "#             nn.GELU(),\n",
    "            nn.LeakyReLU(negative_slope = self.alpha).to(device),\n",
    "            nn.Linear(hidden_dim, num_classes).to(device)\n",
    "        )\n",
    "#         print(self.modules())\n",
    "        for m in self.mlp_head.modules():\n",
    "            print(m)\n",
    "            if isinstance(m, nn.Linear):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#                 m.bias.data.zero_()\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.normal_(m.weight, mean=0, std=np.sqrt(2./m.out_features))\n",
    "\n",
    "    def forward(self, img, mask=None):\n",
    "        p = self.patch_size\n",
    "\n",
    "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=p, p2=p).to(device)\n",
    "        x = self.patch_to_embedding(x).to(device)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        print(x.shape)\n",
    "        x = self.to_cls_token(x[:, 0])\n",
    "        print(x.shape)\n",
    "        return self.mlp_head(x)/np.sqrt(1+self.alpha*self.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, data_loader, loss_history):\n",
    "    total_samples = len(data_loader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = F.log_softmax(model(data), dim=1)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "            loss_history.append(loss.item())\n",
    "        return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, loss_history):\n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "    loss_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            loss_list.append(loss.item())\n",
    "            correct_samples += pred.eq(target).sum()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "#     loss_history.append(avg_loss)\n",
    "    loss_history.append(loss_list)\n",
    "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
    "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
    "          '{:5}'.format(total_samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 400\n",
    "\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "alphalist = [-2,-1,0,0.01]\n",
    "train_losses = {}\n",
    "test_losses = {}\n",
    "for alpha in alphalist:\n",
    "    start_time = time.time()\n",
    "    model = ViT(image_size=28, patch_size=7, num_classes=10, channels=1,\n",
    "                dim=64, depth=6, heads=8, mlp_dim=8192, hidden_dim = 8192, alpha = alpha)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_loss_history, test_loss_history = [], []\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        print('Epoch:', epoch)\n",
    "        train_loss_history = train_epoch(model, optimizer, train_loader, train_loss_history)\n",
    "        test_loss_history = evaluate(model, test_loader, test_loss_history)\n",
    "    train_losses[alpha] = train_loss_history\n",
    "    test_losses[alpha] = test_loss_history\n",
    "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_losses, 'tf_leaky_result_train_mnist'+str(filenum).zfill(3)+'_'+str(expid).zfill(3)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_losses, 'tf_leaky_result_test_mnist'+str(filenum).zfill(3)+'_'+str(expid).zfill(3)+'.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (my_pytorch_env_1)",
   "language": "python",
   "name": "my_pytorch_env_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
